{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train a transfer learning based Semantic segmentation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEEw8IR9smGJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b36bf0b-8c00-4f57-8cab-1e20feda9f4f"
      },
      "source": [
        "import keras\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from types import MethodType\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from os.path import exists, join, basename\n",
        "\n",
        "IMAGE_ORDERING = 'channels_last'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9cHA96a6CsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_url = \"https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo0roPmt7gnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_segmentation_model( input , output ):\n",
        "\n",
        "\timg_input = input\n",
        "\to = output\n",
        "\n",
        "\to_shape = Model(img_input , o ).output_shape\n",
        "\ti_shape = Model(img_input , o ).input_shape\n",
        "\n",
        "\toutput_height = o_shape[1]\n",
        "\toutput_width = o_shape[2]\n",
        "\tinput_height = i_shape[1]\n",
        "\tinput_width = i_shape[2]\n",
        "\tn_classes = o_shape[3]\n",
        "\to = (Reshape((   output_height*output_width , -1    )))(o)\n",
        "\n",
        "\to = (Activation('softmax'))(o)\n",
        "\tmodel = Model( img_input , o )\n",
        "\tmodel.output_width = output_width\n",
        "\tmodel.output_height = output_height\n",
        "\tmodel.n_classes = n_classes\n",
        "\tmodel.input_height = input_height\n",
        "\tmodel.input_width = input_width\n",
        "\tmodel.model_name = \"\"\n",
        "\n",
        "\tmodel.train = MethodType( train , model )\n",
        "\tmodel.predict_segmentation = MethodType( predict , model )\n",
        "\tmodel.predict_multiple = MethodType( predict_multiple , model )\n",
        "\tmodel.evaluate_segmentation = MethodType( evaluate , model )\n",
        "\n",
        "\n",
        "\treturn model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOUFAieX6RwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_vgg_encoder(input_height=224,input_width=224,pretrained='imagenet'):\n",
        "    print(type(input_height))\n",
        "    img_input = Input(shape=(input_height,input_width,3))\n",
        "\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format=IMAGE_ORDERING )(img_input)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', data_format=IMAGE_ORDERING )(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool', data_format=IMAGE_ORDERING )(x)\n",
        "    f1 = x\n",
        "\t# Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', data_format=IMAGE_ORDERING )(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', data_format=IMAGE_ORDERING )(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool', data_format=IMAGE_ORDERING )(x)\n",
        "    f2 = x\n",
        "\n",
        "\t# Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', data_format=IMAGE_ORDERING )(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', data_format=IMAGE_ORDERING )(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', data_format=IMAGE_ORDERING )(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool', data_format=IMAGE_ORDERING )(x)\n",
        "    f3 = x\n",
        "\n",
        "\t# Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', data_format=IMAGE_ORDERING )(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', data_format=IMAGE_ORDERING )(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', data_format=IMAGE_ORDERING )(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool', data_format=IMAGE_ORDERING )(x)\n",
        "    f4 = x\n",
        "\n",
        "\t# Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', data_format=IMAGE_ORDERING )(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', data_format=IMAGE_ORDERING )(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', data_format=IMAGE_ORDERING )(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool', data_format=IMAGE_ORDERING )(x)\n",
        "    f5 = x\n",
        "\n",
        "\t\n",
        "    if(pretrained == 'imagenet'):\n",
        "        VGG_Weights_path = keras.utils.get_file(pretrained_url.split(\"/\")[-1],pretrained_url)\n",
        "        Model(img_input,x).load_weights(VGG_Weights_path)\n",
        "\n",
        "\n",
        "    return img_input , [f1 , f2 , f3 , f4 , f5 ]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxoGbWAs6-z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _unet( n_classes , encoder , l1_skip_conn=True,  input_height=416, input_width=608  ):\n",
        "\n",
        "\timg_input , levels = encoder( input_height=input_height ,  input_width=input_width )\n",
        "\t[f1 , f2 , f3 , f4 , f5 ] = levels \n",
        "\n",
        "\to = f4\n",
        "\n",
        "\to = ( ZeroPadding2D( (1,1) , data_format=IMAGE_ORDERING ))(o)\n",
        "\to = ( Conv2D(512, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
        "\to = ( BatchNormalization())(o)\n",
        "\n",
        "\to = ( UpSampling2D( (2,2), data_format=IMAGE_ORDERING))(o)\n",
        "\to = ( concatenate([ o ,f3],axis=MERGE_AXIS )  )\n",
        "\to = ( ZeroPadding2D( (1,1), data_format=IMAGE_ORDERING))(o)\n",
        "\to = ( Conv2D( 256, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
        "\to = ( BatchNormalization())(o)\n",
        "\n",
        "\to = ( UpSampling2D( (2,2), data_format=IMAGE_ORDERING))(o)\n",
        "\to = ( concatenate([o,f2],axis=MERGE_AXIS ) )\n",
        "\to = ( ZeroPadding2D((1,1) , data_format=IMAGE_ORDERING ))(o)\n",
        "\to = ( Conv2D( 128 , (3, 3), padding='valid' , data_format=IMAGE_ORDERING ) )(o)\n",
        "\to = ( BatchNormalization())(o)\n",
        "\n",
        "\to = ( UpSampling2D( (2,2), data_format=IMAGE_ORDERING))(o)\n",
        "\t\n",
        "\tif l1_skip_conn:\n",
        "\t\to = ( concatenate([o,f1],axis=MERGE_AXIS ) )\n",
        "\n",
        "\to = ( ZeroPadding2D((1,1)  , data_format=IMAGE_ORDERING ))(o)\n",
        "\to = ( Conv2D( 64 , (3, 3), padding='valid'  , data_format=IMAGE_ORDERING ))(o)\n",
        "\to = ( BatchNormalization())(o)\n",
        "\n",
        "\to =  Conv2D( n_classes , (3, 3) , padding='same', data_format=IMAGE_ORDERING )( o )\n",
        "\t\n",
        "\tmodel = get_segmentation_model(img_input , o )\n",
        "\n",
        "\n",
        "\treturn model\n",
        "\n",
        "\n",
        "def vgg_unet( n_classes,input_height=416,input_width=608,encoder_level=3):\n",
        "\n",
        "\tmodel =  _unet( n_classes, get_vgg_encoder,input_height=input_height, input_width=input_width  )\n",
        "\tmodel.model_name = \"vgg_unet\"\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFGMltVDSsqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cwd = os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZqTk4iJSbpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_name = join(cwd, 'warwick_qu_dataset_released_2016_07_08')\n",
        "if not exists(dataset_name + '.zip'):\n",
        "  get_ipython().system('wget https://warwick.ac.uk/fac/sci/dcs/research/tia/glascontest/download/warwick_qu_dataset_released_2016_07_08.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bouZ6q1UAi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_dir = join(cwd, 'Warwick QU Dataset (Released 2016_07_08)')\n",
        "if not exists(dataset_dir):\n",
        "  get_ipython().system('unzip ' + dataset_name + '.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFIGu2DCXChu",
        "colab_type": "code",
        "outputId": "3768b926-33f3-4788-ee33-9fec5a3cb607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "data = pd.read_csv(join(dataset_dir, 'Grade.csv')) \n",
        "data['seg_name'] = [name + '_anno.bmp' for name in data['name']]\n",
        "data = data[['name', 'seg_name']]\n",
        "data['name'] = [name + '.bmp' for name in data['name']]\n",
        "#print(data.columns[2])\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>seg_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>testA_1.bmp</td>\n",
              "      <td>testA_1_anno.bmp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>testA_10.bmp</td>\n",
              "      <td>testA_10_anno.bmp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>testA_11.bmp</td>\n",
              "      <td>testA_11_anno.bmp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>testA_12.bmp</td>\n",
              "      <td>testA_12_anno.bmp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>testA_13.bmp</td>\n",
              "      <td>testA_13_anno.bmp</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           name           seg_name\n",
              "0   testA_1.bmp   testA_1_anno.bmp\n",
              "1  testA_10.bmp  testA_10_anno.bmp\n",
              "2  testA_11.bmp  testA_11_anno.bmp\n",
              "3  testA_12.bmp  testA_12_anno.bmp\n",
              "4  testA_13.bmp  testA_13_anno.bmp"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTwJNXCfRrpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ird6GYqQqUA7",
        "colab_type": "code",
        "outputId": "01c30474-35be-406e-e93d-2353b11aa17d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "train_df = data[data.name.str.startswith('train')]\n",
        "print(train_df.shape)\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(85, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>seg_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>train_1.bmp</td>\n",
              "      <td>train_1_anno.bmp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>train_10.bmp</td>\n",
              "      <td>train_10_anno.bmp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>train_11.bmp</td>\n",
              "      <td>train_11_anno.bmp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>train_12.bmp</td>\n",
              "      <td>train_12_anno.bmp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>train_13.bmp</td>\n",
              "      <td>train_13_anno.bmp</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            name           seg_name\n",
              "80   train_1.bmp   train_1_anno.bmp\n",
              "81  train_10.bmp  train_10_anno.bmp\n",
              "82  train_11.bmp  train_11_anno.bmp\n",
              "83  train_12.bmp  train_12_anno.bmp\n",
              "84  train_13.bmp  train_13_anno.bmp"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhQoS_Taq-67",
        "colab_type": "code",
        "outputId": "e449aba0-a882-44d9-8d7b-477396d1125a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "valid_df = data[data.name.str.startswith('testA')]\n",
        "print(valid_df.shape)\n",
        "valid_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>seg_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>testA_1.bmp</td>\n",
              "      <td>testA_1_anno.bmp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>testA_10.bmp</td>\n",
              "      <td>testA_10_anno.bmp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>testA_11.bmp</td>\n",
              "      <td>testA_11_anno.bmp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>testA_12.bmp</td>\n",
              "      <td>testA_12_anno.bmp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>testA_13.bmp</td>\n",
              "      <td>testA_13_anno.bmp</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           name           seg_name\n",
              "0   testA_1.bmp   testA_1_anno.bmp\n",
              "1  testA_10.bmp  testA_10_anno.bmp\n",
              "2  testA_11.bmp  testA_11_anno.bmp\n",
              "3  testA_12.bmp  testA_12_anno.bmp\n",
              "4  testA_13.bmp  testA_13_anno.bmp"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5IpelkyQUDh",
        "colab_type": "code",
        "outputId": "6d3b375a-54a2-49d6-b733-965d48e39ef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i, j in data.iterrows(): \n",
        "    print(j[1]) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testA_1_anno.bmp\n",
            "testA_10_anno.bmp\n",
            "testA_11_anno.bmp\n",
            "testA_12_anno.bmp\n",
            "testA_13_anno.bmp\n",
            "testA_14_anno.bmp\n",
            "testA_15_anno.bmp\n",
            "testA_16_anno.bmp\n",
            "testA_17_anno.bmp\n",
            "testA_18_anno.bmp\n",
            "testA_19_anno.bmp\n",
            "testA_2_anno.bmp\n",
            "testA_20_anno.bmp\n",
            "testA_21_anno.bmp\n",
            "testA_22_anno.bmp\n",
            "testA_23_anno.bmp\n",
            "testA_24_anno.bmp\n",
            "testA_25_anno.bmp\n",
            "testA_26_anno.bmp\n",
            "testA_27_anno.bmp\n",
            "testA_28_anno.bmp\n",
            "testA_29_anno.bmp\n",
            "testA_3_anno.bmp\n",
            "testA_30_anno.bmp\n",
            "testA_31_anno.bmp\n",
            "testA_32_anno.bmp\n",
            "testA_33_anno.bmp\n",
            "testA_34_anno.bmp\n",
            "testA_35_anno.bmp\n",
            "testA_36_anno.bmp\n",
            "testA_37_anno.bmp\n",
            "testA_38_anno.bmp\n",
            "testA_39_anno.bmp\n",
            "testA_4_anno.bmp\n",
            "testA_40_anno.bmp\n",
            "testA_41_anno.bmp\n",
            "testA_42_anno.bmp\n",
            "testA_43_anno.bmp\n",
            "testA_44_anno.bmp\n",
            "testA_45_anno.bmp\n",
            "testA_46_anno.bmp\n",
            "testA_47_anno.bmp\n",
            "testA_48_anno.bmp\n",
            "testA_49_anno.bmp\n",
            "testA_5_anno.bmp\n",
            "testA_50_anno.bmp\n",
            "testA_51_anno.bmp\n",
            "testA_52_anno.bmp\n",
            "testA_53_anno.bmp\n",
            "testA_54_anno.bmp\n",
            "testA_55_anno.bmp\n",
            "testA_56_anno.bmp\n",
            "testA_57_anno.bmp\n",
            "testA_58_anno.bmp\n",
            "testA_59_anno.bmp\n",
            "testA_6_anno.bmp\n",
            "testA_60_anno.bmp\n",
            "testA_7_anno.bmp\n",
            "testA_8_anno.bmp\n",
            "testA_9_anno.bmp\n",
            "testB_1_anno.bmp\n",
            "testB_10_anno.bmp\n",
            "testB_11_anno.bmp\n",
            "testB_12_anno.bmp\n",
            "testB_13_anno.bmp\n",
            "testB_14_anno.bmp\n",
            "testB_15_anno.bmp\n",
            "testB_16_anno.bmp\n",
            "testB_17_anno.bmp\n",
            "testB_18_anno.bmp\n",
            "testB_19_anno.bmp\n",
            "testB_2_anno.bmp\n",
            "testB_20_anno.bmp\n",
            "testB_3_anno.bmp\n",
            "testB_4_anno.bmp\n",
            "testB_5_anno.bmp\n",
            "testB_6_anno.bmp\n",
            "testB_7_anno.bmp\n",
            "testB_8_anno.bmp\n",
            "testB_9_anno.bmp\n",
            "train_1_anno.bmp\n",
            "train_10_anno.bmp\n",
            "train_11_anno.bmp\n",
            "train_12_anno.bmp\n",
            "train_13_anno.bmp\n",
            "train_14_anno.bmp\n",
            "train_15_anno.bmp\n",
            "train_16_anno.bmp\n",
            "train_17_anno.bmp\n",
            "train_18_anno.bmp\n",
            "train_19_anno.bmp\n",
            "train_2_anno.bmp\n",
            "train_20_anno.bmp\n",
            "train_21_anno.bmp\n",
            "train_22_anno.bmp\n",
            "train_23_anno.bmp\n",
            "train_24_anno.bmp\n",
            "train_25_anno.bmp\n",
            "train_26_anno.bmp\n",
            "train_27_anno.bmp\n",
            "train_28_anno.bmp\n",
            "train_29_anno.bmp\n",
            "train_3_anno.bmp\n",
            "train_30_anno.bmp\n",
            "train_31_anno.bmp\n",
            "train_32_anno.bmp\n",
            "train_33_anno.bmp\n",
            "train_34_anno.bmp\n",
            "train_35_anno.bmp\n",
            "train_36_anno.bmp\n",
            "train_37_anno.bmp\n",
            "train_38_anno.bmp\n",
            "train_39_anno.bmp\n",
            "train_4_anno.bmp\n",
            "train_40_anno.bmp\n",
            "train_41_anno.bmp\n",
            "train_42_anno.bmp\n",
            "train_43_anno.bmp\n",
            "train_44_anno.bmp\n",
            "train_45_anno.bmp\n",
            "train_46_anno.bmp\n",
            "train_47_anno.bmp\n",
            "train_48_anno.bmp\n",
            "train_49_anno.bmp\n",
            "train_5_anno.bmp\n",
            "train_50_anno.bmp\n",
            "train_51_anno.bmp\n",
            "train_52_anno.bmp\n",
            "train_53_anno.bmp\n",
            "train_54_anno.bmp\n",
            "train_55_anno.bmp\n",
            "train_56_anno.bmp\n",
            "train_57_anno.bmp\n",
            "train_58_anno.bmp\n",
            "train_59_anno.bmp\n",
            "train_6_anno.bmp\n",
            "train_60_anno.bmp\n",
            "train_61_anno.bmp\n",
            "train_62_anno.bmp\n",
            "train_63_anno.bmp\n",
            "train_64_anno.bmp\n",
            "train_65_anno.bmp\n",
            "train_66_anno.bmp\n",
            "train_67_anno.bmp\n",
            "train_68_anno.bmp\n",
            "train_69_anno.bmp\n",
            "train_7_anno.bmp\n",
            "train_70_anno.bmp\n",
            "train_71_anno.bmp\n",
            "train_72_anno.bmp\n",
            "train_73_anno.bmp\n",
            "train_74_anno.bmp\n",
            "train_75_anno.bmp\n",
            "train_76_anno.bmp\n",
            "train_77_anno.bmp\n",
            "train_78_anno.bmp\n",
            "train_79_anno.bmp\n",
            "train_8_anno.bmp\n",
            "train_80_anno.bmp\n",
            "train_81_anno.bmp\n",
            "train_82_anno.bmp\n",
            "train_83_anno.bmp\n",
            "train_84_anno.bmp\n",
            "train_85_anno.bmp\n",
            "train_9_anno.bmp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q7BO0dKHN14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import itertools\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "import random\n",
        "\n",
        "random.seed(0)\n",
        "class_colors = [  ( random.randint(0,255),random.randint(0,255),random.randint(0,255)   ) for _ in range(5000)  ]\n",
        "\n",
        "\n",
        "def get_pairs_from_paths( df):\n",
        "\tret = []\n",
        "\n",
        "\tfor _, names in df.iterrows(names):\n",
        "\t\tim = os.path.join(dataset_dir, names[0])\n",
        "\t\tseg = os.path.join( dataset_dir, names[1])\n",
        "\t\tret.append((im , seg))\n",
        "\n",
        "\treturn ret\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_image_arr( path , width , height , imgNorm=\"sub_mean\" , odering='channels_first' ):\n",
        "\n",
        "\n",
        "\tif type( path ) is np.ndarray:\n",
        "\t\timg = path\n",
        "\telse:\n",
        "\t\timg = cv2.imread(path, 1)\n",
        "\n",
        "\tif imgNorm == \"sub_and_divide\":\n",
        "\t\timg = np.float32(cv2.resize(img, ( width , height ))) / 127.5 - 1\n",
        "\telif imgNorm == \"sub_mean\":\n",
        "\t\timg = cv2.resize(img, ( width , height ))\n",
        "\t\timg = img.astype(np.float32)\n",
        "\t\timg[:,:,0] -= 103.939\n",
        "\t\timg[:,:,1] -= 116.779\n",
        "\t\timg[:,:,2] -= 123.68\n",
        "\t\timg = img[ : , : , ::-1 ]\n",
        "\telif imgNorm == \"divide\":\n",
        "\t\timg = cv2.resize(img, ( width , height ))\n",
        "\t\timg = img.astype(np.float32)\n",
        "\t\timg = img/255.0\n",
        "\n",
        "\treturn img\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_segmentation_arr( path , nClasses ,  width , height , no_reshape=False ):\n",
        "\n",
        "\tseg_labels = np.zeros((  height , width  , nClasses ))\n",
        "\t\t\n",
        "\tif type( path ) is np.ndarray:\n",
        "\t\timg = path\n",
        "\telse:\n",
        "\t\timg = cv2.imread(path, 1)\n",
        "\n",
        "\timg = cv2.resize(img, ( width , height ) , interpolation=cv2.INTER_NEAREST )\n",
        "\timg = img[:, : , 0]\n",
        "\n",
        "\tfor c in range(nClasses):\n",
        "\t\tseg_labels[: , : , c ] = (img == c ).astype(int)\n",
        "\n",
        "\n",
        "\t\n",
        "\tif no_reshape:\n",
        "\t\treturn seg_labels\n",
        "\n",
        "\tseg_labels = np.reshape(seg_labels, ( width*height , nClasses ))\n",
        "\treturn seg_labels\n",
        "\n",
        "def image_segmentation_generator( images_path , segs_path ,  batch_size,  n_classes , input_height , input_width , output_height , output_width):\n",
        "\t\n",
        "\timg_seg_pairs = get_pairs_from_paths( images_path , segs_path )\n",
        "\trandom.shuffle( img_seg_pairs )\n",
        "\tzipped = itertools.cycle( img_seg_pairs  )\n",
        "\n",
        "\twhile True:\n",
        "\t\tX = []\n",
        "\t\tY = []\n",
        "\t\tfor _ in range( batch_size) :\n",
        "\t\t\tim , seg = next(zipped) \n",
        "\n",
        "\t\t\tim = cv2.imread(im , 1 )\n",
        "\t\t\tseg = cv2.imread(seg , 1 )\n",
        "\n",
        "\t\t\tX.append( get_image_arr(im , input_width , input_height ,odering=IMAGE_ORDERING )  )\n",
        "\t\t\tY.append( get_segmentation_arr( seg , n_classes , output_width , output_height )  )\n",
        "\n",
        "\t\tyield np.array(X) , np.array(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGNkj2pu7eY-",
        "colab_type": "code",
        "outputId": "a0620f25-ea22-4f01-8515-1c71fe74d05d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "source": [
        "input_height=224 , \n",
        "input_width=224 , \n",
        "n_classes=2,\n",
        "checkpoints_path= '/content', \n",
        "epochs = 5,\n",
        "batch_size = 2,\n",
        "steps_per_epoch=12,\n",
        "#optimizer_name='sgd' \n",
        "\n",
        "\n",
        "model = vgg_unet(n_classes,input_height,input_width)\n",
        "   \n",
        "n_classes = model.n_classes\n",
        "input_height = model.input_height\n",
        "input_width = model.input_width\n",
        "output_height = model.output_height\n",
        "output_width = model.output_width\n",
        "model.compile(keras.optimizers.Adam(lr = 0.0001), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "train_gen = image_segmentation_generator(train_images,train_annotations,batch_size,n_classes,input_height , input_width , output_height,output_width)\n",
        "\n",
        "val_gen  = image_segmentation_generator( val_images , val_annotations ,  val_batch_size,  n_classes , input_height , input_width , output_height,output_width)\n",
        "\n",
        "model.fit_generator( train_gen , steps_per_epoch  , validation_split=val_gen , validation_steps=200 ,  epochs=epochs )\n",
        "if not checkpoints_path is None:\n",
        "\tmodel.save_weights(checkpoints_path + \".\" + str(epochs))\n",
        "\tprint(\"saved \",checkpoints_path + \".model.\" + str(epochs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tuple'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mmake_shape\u001b[0;34m(v, arg_name)\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mas_shape\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m   1203\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0;31m# Got a list of dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mas_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0;31m# Got a list of dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mas_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mas_dimension\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    715\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m       if (not isinstance(value, compat.bytes_or_text_types) and\n",
            "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'tuple'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-0ca172484140>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg_unet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_height\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-350edd0688e2>\u001b[0m in \u001b[0;36mvgg_unet\u001b[0;34m(n_classes, input_height, input_width, encoder_level)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvgg_unet\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_height\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m608\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0m_unet\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_vgg_encoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_height\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_width\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"vgg_unet\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-350edd0688e2>\u001b[0m in \u001b[0;36m_unet\u001b[0;34m(n_classes, encoder, l1_skip_conn, input_height, input_width)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_unet\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0ml1_skip_conn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0minput_height\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m608\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mimg_input\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minput_height\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_height\u001b[0m \u001b[0;34m,\u001b[0m  \u001b[0minput_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_width\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mf1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mf3\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mf4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mf5\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-d63f033cbfef>\u001b[0m in \u001b[0;36mget_vgg_encoder\u001b[0;34m(input_height, input_width, pretrained)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_vgg_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_height\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimg_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_height\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'block1_conv1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMAGE_ORDERING\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_shape, name, dtype, sparse, tensor)\u001b[0m\n\u001b[1;32m    176\u001b[0m                              \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                              \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                              input_tensor=tensor)\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0;31m# Return tensor including _keras_shape and _keras_history.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# Note that in this case train_output and test_output are the same pointer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, batch_size, batch_input_shape, dtype, input_tensor, sparse, name)\u001b[0m\n\u001b[1;32m     85\u001b[0m                                          \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                                          \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                                          name=self.name)\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(shape, ndim, dtype, sparse, name)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_placeholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   2141\u001b[0m                        \"eager execution.\")\n\u001b[1;32m   2142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2143\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   6258\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6259\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6260\u001b[0;31m   \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6261\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   6262\u001b[0m         \"Placeholder\", dtype=dtype, shape=shape, name=name)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mmake_shape\u001b[0;34m(v, arg_name)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error converting %s to a TensorShape: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     raise ValueError(\"Error converting %s to a TensorShape: %s.\" % (arg_name,\n",
            "\u001b[0;31mTypeError\u001b[0m: Error converting shape to a TensorShape: int() argument must be a string, a bytes-like object or a number, not 'tuple'."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r13iyP_RgcFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}